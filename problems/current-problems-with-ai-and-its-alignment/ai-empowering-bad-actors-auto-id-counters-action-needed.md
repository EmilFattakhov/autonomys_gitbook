---
description: 'Problem: too early to talk about AutoID just yet? Remove solution section!'
---

# AI empowering bad actors, Auto ID counters (action needed)

#### DeepFake Attacks

Artificial intelligence is rapidly advancing, bringing both immense potential and alarming risks. As AI systems grow more sophisticated, they empower malicious actors like scammers, fraudsters, and those seeking to undermine democratic processes. Deepfake technology powered by AI can generate highly realistic yet completely fabricated video and audio content to deceive people. In one chilling case, a Hong Kong finance firm fell victim to a $25 million deepfake fraud scam.

[https://incode.com/blog/25-million-deepfake-fraud-hong-kong/](https://incode.com/blog/25-million-deepfake-fraud-hong-kong/)

#### Problems with Biometric ID

Other networks have emerged approaching the identity problem with personally invasive techniques. WorldCoin's iris-scanning biometric identity network aim to provide a secure form of identification, yet they also raise significant privacy and civil liberties concerns. By requiring the collection of highly sensitive biometric data linked to people's physical identities, such centralized databases create risks if the information is abused by bad actors.

Deepfake AI could potentially exploit the biometric data to generate utterly convincing impersonations of specific individuals for nefarious purposes like fraud, framing innocents for crimes, or producing incendiary disinformation content designed to sow social discord. Authoritarian regimes could pair deepfakes with the biometric data to fabricate fake "evidence" persecuting dissidents or minority groups. Given AI's potent capabilities in this domain, amassing centralized biometric databases provides a concerning attack vector that malicious actors could weaponize for large-scale abuse and subjugation if accessed.

[https://www.gao.gov/assets/gao-20-379sp.pdf](https://www.gao.gov/assets/gao-20-379sp.pdf) [https://www.infosecurity-magazine.com/news/goldpickaxe-trojan-biometric/](https://www.infosecurity-magazine.com/news/goldpickaxe-trojan-biometric/)

#### LLM Misinformation Consequences

Large language models can also proliferate misinformation and disinformation at an unprecedented scale, with potentially catastrophic consequences during election cycles. As a U.S. Government report warned, AI-generated misinformation could severely disrupt fair elections by flooding the information landscape with fake content indistinguishable from the truth. This threat has already begun manifesting, with major tech companies like Google and OpenAI detecting widespread AI-enabled disinformation campaigns attempting to sway public opinion on political issues.

[https://fortune.com/2024/02/27/election-misinformation-genai-chatbots-google-openai/](https://fortune.com/2024/02/27/election-misinformation-genai-chatbots-google-openai/)

The ramifications of AI being weaponized by bad actors are severe and far-reaching. Safeguards must be implemented to prevent such abuses and uphold trust as AI capabilities grow exponentially.

### Our Solution: AutoID

#### Auto ID and Human/AI Identification

To maintain trust online in this age of AI, we urgently need a robust system for identifying and authenticating autonomous entities on the internet. Auto ID provides such a solution by allowing any AI system or human to obtain a verified digital identity. Unlike initiatives like WorldCoinâ€™s World ID which can only issue biometric IDs to humans, Auto ID encompasses all autonomous actors - both artificial and human. With Auto ID, you can reliably determine whether the content or actions you encounter stem from an AI or human agent. This transparency enables informed trust decisions when engaging with different entities online.

#### Auto ID and LLM Misinformation

Crucially, Auto ID provides a solution to combat the proliferation of AI-generated misinformation and disinformation online. By issuing verifiable digital identities to both human users and AI systems, Auto ID allows content to be cryptographically signed and attributed to its true source. This transparency empowers people to easily distinguish truth from fiction by identifying whether the content originated from a trusted entity or an unknown, potentially nefarious AI model. Legitimate organizations, experts, and public figures can use Auto ID to certify their authentic messaging gets through the noise of AI-generated falsehoods. Conversely, anonymously spread misinformation produced by unverified AI assistants would lack this trusted provenance.

#### Auto ID and AI Agent Trust

Moreover, Auto ID lets you designate authorized AI assistants to operate on your behalf for certain approved domains, building trust through consent and oversight. As AI capabilities exponentially grow, having an open yet secure framework is critical for continuing safe AI development and responsible human-AI interaction online.
